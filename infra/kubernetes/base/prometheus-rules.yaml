apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ecommerce-alerts
  namespace: observability
  labels:
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
    - name: infrastructure
      interval: 30s
      rules:
        - alert: ServiceDown
          expr: up{job=~".*-service|api-gateway"} == 0
          for: 2m
          labels:
            severity: critical
            category: infrastructure
          annotations:
            summary: "Service {{ $labels.job }} is down"
            description: "Service {{ $labels.job }} in namespace {{ $labels.namespace }} has been down for more than 2 minutes."
            
        - alert: HighMemoryUsage
          expr: (container_memory_working_set_bytes{pod=~".*-service.*|api-gateway.*"} / container_spec_memory_limit_bytes{pod=~".*-service.*|api-gateway.*"}) > 0.85
          for: 5m
          labels:
            severity: warning
            category: infrastructure
          annotations:
            summary: "High memory usage on {{ $labels.pod }}"
            description: "Pod {{ $labels.pod }} is using {{ $value | humanizePercentage }} of memory limit."
            
        - alert: HighCPUUsage
          expr: (rate(container_cpu_usage_seconds_total{pod=~".*-service.*|api-gateway.*"}[5m]) / container_spec_cpu_quota{pod=~".*-service.*|api-gateway.*"} * 100000) > 80
          for: 5m
          labels:
            severity: warning
            category: infrastructure
          annotations:
            summary: "High CPU usage on {{ $labels.pod }}"
            description: "Pod {{ $labels.pod }} is using high CPU for more than 5 minutes."
            
        - alert: PodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total{pod=~".*-service.*|api-gateway.*"}[15m]) > 0
          for: 5m
          labels:
            severity: critical
            category: infrastructure
          annotations:
            summary: "Pod {{ $labels.pod }} is crash looping"
            description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is restarting frequently."

    - name: application_performance
      interval: 30s
      rules:
        - alert: HighResponseTime
          expr: histogram_quantile(0.95, sum(rate(http_server_requests_seconds_bucket{uri!~"/actuator.*"}[5m])) by (le, application, uri)) > 2
          for: 5m
          labels:
            severity: warning
            category: performance
          annotations:
            summary: "High response time on {{ $labels.application }}"
            description: "95th percentile response time for {{ $labels.application }}{{ $labels.uri }} is {{ $value }}s (threshold: 2s)."
            
        - alert: HighErrorRate
          expr: (sum(rate(http_server_requests_seconds_count{status=~"5.."}[5m])) by (application) / sum(rate(http_server_requests_seconds_count[5m])) by (application)) > 0.05
          for: 3m
          labels:
            severity: critical
            category: performance
          annotations:
            summary: "High error rate on {{ $labels.application }}"
            description: "Error rate for {{ $labels.application }} is {{ $value | humanizePercentage }} (threshold: 5%)."
            
        - alert: CircuitBreakerOpen
          expr: resilience4j_circuitbreaker_state{state="open"} == 1
          for: 2m
          labels:
            severity: warning
            category: resilience
          annotations:
            summary: "Circuit breaker open for {{ $labels.name }}"
            description: "Circuit breaker {{ $labels.name }} in {{ $labels.application }} is open, requests are being rejected."

    - name: business_metrics
      interval: 60s
      rules:
        - alert: LowOrderCreationRate
          expr: rate(orders_created_total[10m]) < 0.01
          for: 15m
          labels:
            severity: warning
            category: business
          annotations:
            summary: "Low order creation rate"
            description: "Order creation rate is {{ $value }} orders/sec, which is below expected threshold during business hours."
            
        - alert: HighPaymentDeclineRate
          expr: (sum(rate(payments_processed_total{status="DECLINED"}[5m])) / sum(rate(payments_processed_total[5m]))) > 0.15
          for: 5m
          labels:
            severity: warning
            category: business
          annotations:
            summary: "High payment decline rate"
            description: "Payment decline rate is {{ $value | humanizePercentage }} (threshold: 15%)."
            
        - alert: HighPaymentFailureRate
          expr: (sum(rate(payments_processed_total{status="FAILED"}[5m])) / sum(rate(payments_processed_total[5m]))) > 0.10
          for: 5m
          labels:
            severity: critical
            category: business
          annotations:
            summary: "High payment failure rate"
            description: "Payment failure rate is {{ $value | humanizePercentage }} (threshold: 10%). Technical issues detected."
            
        - alert: LowStockAlert
          expr: product_stock_gauge < 10
          for: 1m
          labels:
            severity: info
            category: business
          annotations:
            summary: "Low stock for product {{ $labels.product_id }}"
            description: "Product {{ $labels.product_title }} has only {{ $value }} units in stock."
            
        - alert: HighCartAbandonmentRate
          expr: cart_abandonment_rate > 0.7
          for: 10m
          labels:
            severity: warning
            category: business
          annotations:
            summary: "High cart abandonment rate"
            description: "Cart abandonment rate is {{ $value | humanizePercentage }}, indicating potential UX issues."
            
        - alert: NoUserRegistrations
          expr: rate(users_registered_total[30m]) == 0
          for: 30m
          labels:
            severity: info
            category: business
          annotations:
            summary: "No new user registrations"
            description: "No new users have registered in the last 30 minutes."

    - name: database
      interval: 30s
      rules:
        - alert: HighDatabaseConnections
          expr: hikaricp_connections_active{pool=~".*"} / hikaricp_connections_max{pool=~".*"} > 0.8
          for: 5m
          labels:
            severity: warning
            category: database
          annotations:
            summary: "High database connection usage for {{ $labels.pool }}"
            description: "Database connection pool {{ $labels.pool }} is using {{ $value | humanizePercentage }} of available connections."
            
        - alert: SlowDatabaseQueries
          expr: histogram_quantile(0.95, sum(rate(hikaricp_connections_acquire_seconds_bucket[5m])) by (le, pool)) > 1
          for: 5m
          labels:
            severity: warning
            category: database
          annotations:
            summary: "Slow database connection acquisition"
            description: "95th percentile for acquiring connections from pool {{ $labels.pool }} is {{ $value }}s."
